### <span style = "color: #04CA96">회귀분석이란?
- 회귀분석(Regression Analysis)은 통계학에서 변수들 간의 관계를 분석하는 방법이다.
- 주로 하나의 종속 변수(dependent variable)와 하나 또는 그 이상의 독립 변수(independent variables) 간의 관계를 모델링한다.

- 기본적인 목표는 **독립 변수의 변화가 종속 변수에 어떤 영향을 미치는지 이해하고 예측하는 것**이다.
- 회귀분석은 상관관계를 보여줄 수는 있어도, 인과관계를 입증하지는 않는다.
#### <span style = "color: #557FFF">회귀분석의 중요성
- **예측**: 회귀분석은 독립 변수의 값에 따라 종속 변수의 값을 예측할 수 있다.

- **인과관계의 이해**: 변수들 사이의 관계를 이해하고, 어떤 변수가 다른 변수에 영향을 미치는지 분석한다.
- **의사결정 지원**: 비지니스, 과학, 사회과학 등 다양한 분야에서 데이터에 근거한 의사결정에 도움을 준다.
---
### <span style = "color: #04CA96">회귀분석의 변수

#### <span style = "color: #557FFF">종속 변수(Dependent Variable)
- 영향을받는변수 (𝑦) = 반응변수(Response Variable) = 종속변수(Dependent Variable) = 결과변수(Outcome Variable)
- 우리가 예측하거나 설명하고자 하는 변수이다.
- 회귀분석의 목적은 종속 변수의 변화를 독립 변수를 통해 설명하는 것이다.

- 예: 주택 가격을 예측하는 모델에서 주택 가격은 종속 변수이다.
#### <span style = "color: #557FFF">독립 변수(Independent Variable)
- 영향을주는변수 (𝑥) = 설명변수(Explanatory Variable) = 독립변수(Independent Variable) = 예측변수(Predictor Variable)
- 종속 변수의 변화를 설명하거나 예측하는데 사용되는 변수이다.
- 종속 변수에 영향을 줄 수 있는 요인들로 간주된다.

- 예: 주택 가격을 예측할 때 방의 개수, 위치, 건축 연도 등이 독립 변수가 될 수 있다.
- 너무 많은 독립 변수를 포함시키면 모델이 과적합되어 일반화 성능이 떨어질 수 있다.
---
### <span style = "color: #04CA96">단순 선형 회귀분석
- 하나의 독립 변수와 하나의 종속 변수 간의 선형 관계를 파악하고, 이를 기반으로 예측을 수행하는 것이다.![](https://velog.velcdn.com/images/tngus0325/post/75e3a2a7-9c69-432c-9235-b0764db26f5a/image.png)
#### <span style = "color: #557FFF">최소제곱법
- 회귀선과 데이터 간의 거리(오차)의 제곱을 최소화하는 방식으로. 회귀선의 파라미터를 추정한다.
- 즉, 실제 데이터와 회귀선 사이의 차이를 최소화하는 B0과 B1값을 찾는 것이다.

- 최소제곱법을 통해 얻은 B0과 B1은 데이터를 가장 잘 설명하는 회귀선을 제공한다.
---
### <span style = "color: #04CA96">선형회귀분석의 가정
#### <span style = "color: #557FFF">선형성(Linearity)
- 종속 변수와 독립 변수 간의 관계가 선형이라는 가정이다.

- 산점도(scatter plot)를 통해 변수 간 관계를 시각적으로 확인하거나, 잔차와 예측된 값의 관계를 분석한다.

#### <span style = "color: #557FFF">등분산성(Homoscedasticity)
- 모든 독립 변수의 값에 대해 종속 변수의 잔차가 일정한 분산을 가진다는 가정이다.

- 잔차와 예측된 값의 산점도를 그려서 잔차의 분산이 일정한지 확인한다. 무작위적으로 고루 분포되어야 등분산성 가정을 만족한다.

#### <span style = "color: #557FFF">독립성(Independence)
- 모델의 잔차가 서로 독립적이라는 가정이다.
- Durbin-Waston 통계량을 사용한다.

- 독립성의 위반은 시계열 데이터에서 주로 발생한다.

#### <span style = "color: #557FFF">비상관성(No Multicollinearity)
- 독립 변수들 간에 상관관계가 없어야 한다는 가정이다.

- 상관 행렬(correlation matrix) 또는 분산팽창계수(VIF, Variance Inflation Factor)를 통해 다중공선성을 확인한다.

#### <span style = "color: #557FFF">정상성(정규성)(Normality)
- 모델의 잔차가 정규 분포를 따른다는 가정이다.

- Q-Q Plot, Kolmogorov-Smirnov 검정, Shapiro-Wilk 검정을 사용한다.
---
### <span style = "color: #04CA96">회귀분석에서의 검토사항
#### <span style = "color: #557FFF">회귀계수들이 유의미한가?
- 독립 변수가 종속 변수에 실질적인 영향을 미치는지를 나타낸다.

- 해당 계수의 t-statistics의 p-value(유의확률)가 0.05보다 작으면 해당 회귀계수가 통계적으로 유의하다고 판단한다.
#### <span style = "color: #557FFF">모형이 얼마나 설명력을 갖는가?
- 독립 변수가 종속 변수의 변동을 얼마나 잘 설명하는지를 나타낸다.

- 결정계수(R^2)를 사용한다. 결정계수는 0~1의 값을 가지는데, 값이 1에 가까울수록 모형이 데이터를 잘 설명한다고 볼 수 있다.
#### <span style = "color: #557FFF">모형이 데이터를 잘 적합하고 있는가?
- 모형이 데이터의 패턴을 얼마나 잘 포착하고 있는지를 나타낸다.

- 잔차 분석을 통해 이루어진다. 잔차의 패턴을 분석하여 오차가 무작위로 분포하는지, 그리고 가정들이 만족되는지 확인한다.
---
### <span style = "color: #04CA96">회귀분석에서의 검정
#### <span style = "color: #557FFF">F-검정(F-test)
- 모델 전체가 통계적으로 유의미한지를 검정한다.
- 회귀식의 평균제곱과 오차의 평균제곱의 비율로 계산된다.

- 낮은 F-검정의 p-value(0.05이하)는 모델이 통계적으로 유의미하다는 것이다.

#### <span style = "color: #557FFF">T-검정(T-test)
- 각각의 독립 변수가 종속 변수에 미치는 영향이 통계적으로 유의미한지 평가한다. 즉, 각 독립 변수의 회귀 계수가 0과 유의미하게 다른지를 검정한다.

- 각 독립 변수의 회귀 계수를 그 표준 오차로 나누어 t-값을 계산한다.
- 낮은 t-검정 p-value(0.05이하)는 해당 독립 변수가 통계적으로 유의미하다는 것을 나타낸다.

#### <span style = "color: #557FFF">결정계수(R^2)
- 회귀 모델이 종속 변수의 변동성을 얼마나 잘 설명하는지를 나타낸다.
- 1에서 전체 변동성 중 모델에 의해 설명되지 않는 변동성의 비율을 뺀 값이다.
- 1에 가까울 수록 모델의 설명력이 높다고 할 수 있다.

- **총변동(SST: Sum of Square Total)**: 종속 변수의 전체 변동성이다. SST = SSR + SSE
- **회귀에 의한 변동(SSR: Sum of Square Regression)**: 회귀선에 의해 설명되는 변동성을 나타낸다.
- **잔차에 의한 변동(SSE: Sum of Square Error)**: 회귀선에 의해 설명되지 않는 변동성을 나타낸다.
---
### <span style = "color: #04CA96">다중 선형 회귀분석
- 두 개 이상의 독립변수가 하나의 종속변수에 미치는 영향을 예측하는 회귀분석이다.

- 단순 선형 회귀분석의 확장으로, 복수의 설명 변수를 통해 종속 변수와의 관계를 보다 정밀하게 모델링 할 수 있다.
![](https://velog.velcdn.com/images/tngus0325/post/66d5061b-72a7-402c-a87b-f0c1907652e6/image.png)

#### <span style = "color: #557FFF">모델 전체에 대한 가설(F-검정)
- 모델에 포함된 모든 독립 변수가 종속 변수를 예측하는데 유의미한 기여를 하는지를 검증한다.
- **귀무가설(H0):** 모든 독립 변수의 회귀 계수는 0이다. 즉, 독립 변수들은 종속 변수에 대해 아무런 효과가 없다.

- ** 대립가설(H1)**: 적어도 하나의 독립 변수의 회귀 계수는 0이 아니다. 즉, 해당 변수들 중 하나 이상이 종속 변수에 유의미한 영향을 미친다.
- 유의수준 5%하에서 F-통계량의 p-값이 0.05보다 작으면 추정된 회귀식은 통계적으로 유의하다고 볼 수 있다.
- F-통계량이 크면 p-value가 작아지고 이렇게 되면 귀무가설을 기각하고, 모형이 유의미하다고 결론짓는다.

#### <span style = "color: #557FFF">개별 회귀 계수에 대한 가설(t-검정)
- 각각의 독립 변수가 종속 변수에 미치는 영향이 통계적으로 유의미한지를 평가한다.
- ** 귀무가설(H0)**: 특정 독립 변수의 회귀 계수는 0이다. 즉, 해당 독립 변수가 종속 변수를 예측하는 데 유의미한 영향을 미치지 않는다는 것을 의미한다.

- **대립가설(H1)**: 특정 독립 변수의 회귀 계수는 0이 아니다. 이는 해당 독립 변수가 종속 변수를 예측하는 데 유의미한 영향을 미친다는 것을 의미한다.

- 모든 회귀계수의 유의성이 통계적으로 검증되어야 선택된 변수들의 조합으로 모형을 확인할 수 있다.


#### <span style = "color: #557FFF">다중 선형 회귀분석 다중공선성(Multicollinearity)
- 독립 변수들 간에 높은 상관관계가 존재하는 상황을 말한다.

- **분석팽창계수(VIF, Variance Inflation Factor)**: VIF를 통해 다중공선성의 정도를 측정한다. 일반적으로 4보다 크면 다중공선성이 존재한다고 볼 수 있고, 10보다 크면 심각한 문제가 있는 것으로 해석할 수 있다.

---
### <span style = "color: #04CA96">다중회귀분석의 변수 선택 방법
#### <span style = "color: #557FFF">전진선택법(Forward Selection)
- **방법**: 독립 변수가 하나도 포함되지 않은 모델에서 시작한다. 그리고 각 단계에서 모델에 변수를 하나씩 추가한다. 추가되는 변수는 종속 변수를 예측하는데 가장 유용한 변수이다.

- **기준**: 각 단계에서 변수를 추가하면 모델으 성능이 얼마나 향상되는지를 평가한다.
- **종료 조건**: 더 이상 성능 향상이 없을 때, 혹은 사전에 정한 기준에 도달했을 때 종료한다.
- 한 번 선택한 변수는 제거하지 않는다.

#### <span style = "color: #557FFF">후진선택법(Backward Elimination)
- **방법**: 모든 독립 변수를 포함한 모델에서 시작한다. 그리고 각 단계에서 가장 약한 영향을 미치는 변수를 하나씩 제거한다.

- **기준**: 변수를 제거한 후 모델의 성능 변화를 평가한다.
- **종료 조건**: 모든 남은 변수들이 모델에 중요할 때 혹은 사전에 정한 기준에 도달했을 때 종료한다.
#### <span style = "color: #557FFF">단계적방법(Stepwise Method)
- **방법**: 전진선택법과 후진선택법을 결합한 방법이다. 변수를 하나 추가하고, 그 후  필요에 따라 다시 제거하는 과정을 반복한다.
- ** 기준:** 각 단계에서 변수를 추가하거나 제거한 후 모델의 성능을 평가한다. 추가된 변수에 의해 기존 변수의 중요도가 작아지면 추가된 변수를 제거한다.

- **종료 조건**: 더 이상 성능이 향상되지 않을 때 종료한다.

